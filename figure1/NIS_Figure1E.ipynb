{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667ed3d1-4d80-4060-abd6-d24955859413",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NIS-Seq, Figure 1E written by AH and PK\n",
    "\n",
    "---\n",
    "\n",
    "This script generates figure 1E in [*Cell Type-Agnostic Optical Perturbation Screening Using Nuclear In-Situ Sequencing (NIS-Seq)*](https://www.biorxiv.org/content/10.1101/2024.01.18.576210v1). The goal is to compare the percentage of mapped nuclei of *NIS-Seq* and [*Optical Pooled Screens*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6886477/). \n",
    "\n",
    "\n",
    "The inputs for this script were generated with [*JSB ImageFiend*](https://jsb-lab.bio/opticalscreening/AnalyzeInSituCombined_v1.htm) and consist of the follwing files for each celltype:\n",
    "\n",
    "1. **ExperimentName_NuclearIntensities_normal.txt**\n",
    "    * columns: tile number, nucleus id, thresholded intensity\n",
    "        * *tile*: Tile number, according to order of files loaded; counting from 0\n",
    "        * *nucleus*: Number of the nucleus in that tile, as defined by the masks loaded. Cellpose masks start counting at 1.\n",
    "        * *intensity*: For each nucleus, the maximum intensity over all cycles and channels is indicated; intensity is calculated as the integrated pixel intensity across nuclear masks.\n",
    "2. **ExperimentName_NuclearIntensities_scrambled.txt**\n",
    "    * columns: tile number, nucleus id, thresholded intensity\n",
    "        * *tile*: Tile number, according to order of files loaded; counting from 0\n",
    "        * *nucleus*: Number of the nucleus in that tile, as defined by the masks loaded. Cellpose masks start counting at 1.\n",
    "        * *intensity*: For each nucleus, the maximum intensity over all cycles and channels is indicated; intensity is calculated as the integrated pixel intensity across nuclear masks.\n",
    "    \n",
    "3. **ExperimentName_NuclearSequences.txt**\n",
    "    * columns: tile number, nucleus id, x and y coordinates, barcode sequence, maximal intensity\n",
    "        * *tile*: Tile number, according to order of files loaded; counting from 0\n",
    "        * *nucleus*: Number of the nucleus in that tile, as defined by the masks loaded. Cellpose masks start counting at 1.\n",
    "        * *x*: Pixel-wise center position of each nuclear mask in the first cycle.\n",
    "        * *y*: Pixel-wise center position of each nuclear mask in the first cycle.\n",
    "        * *sequence*: Library-matched consensus sequence detected in a nucleus.\n",
    "        * *max_intensity*: For each nucleus, the maximum intensity over all cycles and channels is indicated; intensity is calculated as the integrated pixel intensity across nuclear \n",
    "    \n",
    "4. **ExperimentName_CellAssignments.txt**\n",
    "    * columns: in-situ_tile, situ_nucleus, in-situ, in-situ_nucleus_x, in-situ_nucleus_y, in-situ_nucleus_area, phenotype_tile, phenotype_cell, phenotype_nucleus_x, phenotype_nucleus_y, phenotype_nucleus_area\n",
    "        * *in-situ_tile*: Tile number, according to order of files loaded; counting from 0\n",
    "        * *in-situ_nucleus*: Number of the nucleus in that tile, as defined by the masks loaded. Cellpose masks start counting at 1\n",
    "        * *in-situ_nucleus_x*: Pixel-wise center position of each nuclear mask in the first cycle\n",
    "        * *in-situ_nucleus_y*: Pixel-wise center position of each nuclear mask in the first cycle\n",
    "        * *in-situ_nucleus_area*: Pixel-wise area of each nuclear mask in the first cycle\n",
    "        * *phenotype_tile*: Tile number, according to order of files loaded; counting from 0\n",
    "        * *phenotype_cell*: Number of the membrane mask in that tile, as defined by the masks loaded. Cellpose masks start counting at 1\n",
    "        * *phenotype_nucleus_x*: Pixel-wise center position of each nuclear mask\n",
    "        * *phenotype_nucleus_y*: Pixel-wise center position of each nuclear mask\n",
    "        * *phenotype_nucleus_area*: Pixel-wise area of each nuclear mask in the phenotype data\n",
    "    \n",
    "The optical pooled screening analysis pipeline can be installed from [*Here*](https://github.com/feldman4/OpticalPooledScreens_2019).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c039adb-ec01-4e43-b938-fcd36add1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optical pooled screening libraries\n",
    "from ops.imports import *\n",
    "from ops.process import Align\n",
    "import ops.firesnake\n",
    "from ops.firesnake import Snake\n",
    "\n",
    "# Plot generation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68700905-910c-48b1-8d50-a0719457cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_nis = '/home/jsblab/nis_analysis/'\n",
    "output = '/home/jsblab/nis_analysis_analysis/'\n",
    "\n",
    "celltypes = set([x.split('_')[0] for x in os.listdir(inp_nis) if x[0] != '.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248b06c-be72-4e52-9f53-cfa50b0cdfbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NIS-Seq analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e393d-0a8b-4df3-b61f-7cbd4ada17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "mapping = {'standard': pd.DataFrame(), 'scrambled': pd.DataFrame()}\n",
    "\n",
    "# Iterate through the celltypes\n",
    "for celltype in celltypes:\n",
    "\n",
    "    \n",
    "    # Load Image Fiend data\n",
    "    nucs = pd.read_csv(inp_nis + f'{celltype}_nuclear_intensities_normal.txt', sep = '\\t')\n",
    "    seqs = pd.read_csv(inp_nis + f'{celltype}_NuclearSequences_normal.txt', sep = '\\t')\n",
    "    \n",
    "    # Scrambled data\n",
    "    nucs_sc = pd.read_csv(inp_nis + f'{celltype}_nuclear_intensities_scrambled.txt', sep = '\\t')\n",
    "    seqs_sc = pd.read_csv(inp_nis + f'{celltype}_NuclearSequences_scrambled.txt', sep = '\\t')\n",
    "    \n",
    "    # In-situ phenotype analysis\n",
    "    assi = pd.read_csv(inp_nis + f'P42_{celltype}_CellAssignments.txt', sep = '\\t')\n",
    "    \n",
    "    # merge sequences with assignments\n",
    "    seqs = seqs.merge(assi, left_on=['tile','nucleus'], right_on=['in-situ_tile','cell'])\n",
    "    tiles = np.unique(seqs.tile).tolist()\n",
    "    mapping['standard'] = pd.concat([mapping['standard'], pd.DataFrame([(celltype, (nucs.tile == tile).sum(), (seqs.tile == tile).sum()) for tile in tiles])])\n",
    "    \n",
    "    # merge sequences with assignments\n",
    "    seqs_sc = seqs_sc.merge(assi, left_on=['tile','nucleus'], right_on=['in-situ_tile','cell'])\n",
    "    tiles = np.unique(seqs_sc.tile).tolist()\n",
    "    mapping['scrambled'] = pd.concat([mapping['scrambled'], pd.DataFrame([(celltype, (nucs_sc.tile == tile).sum(), (seqs_sc.tile == tile).sum()) for tile in tiles])])\n",
    "\n",
    "\n",
    "mapping['standard'] = mapping['standard'].rename({0: 'celltype', 1: 'nucs', 2: 'seqs'}, axis=1)\n",
    "mapping['scrambled'] = mapping['scrambled'].rename({0: 'celltype', 1: 'nucs', 2: 'seqs'}, axis=1)\n",
    "\n",
    "dic = {'standard': {}, 'scrambled': {}}\n",
    "\n",
    "for x in ['standard', 'scrambled']:\n",
    "    for celltype in celltypes:\n",
    "        df_ = mapping[x].query(f'celltype==\"{celltype}\"')\n",
    "\n",
    "        m1 = (df_.iloc[:(len(df_)//2)].seqs.sum() / df_.iloc[:(len(df_)//2)].nucs.sum() * 100).mean()\n",
    "        m2 = (df_.iloc[(len(df_)//2):].seqs.sum() / df_.iloc[(len(df_)//2):].nucs.sum() * 100).mean()\n",
    "\n",
    "        dic[x][celltype] = (m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae3cb5-59af-4319-9e22-be59d5317edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic['standard']).T.rename({0: 'standard', 1: 'standard'}, axis=1)\n",
    "df['0'] = pd.DataFrame(dic['scrambled']).T[0]\n",
    "df['1'] = pd.DataFrame(dic['scrambled']).T[1]\n",
    "\n",
    "\n",
    "df = df.rename({'0': 'scrambled', '1': 'scrambled'}, axis=1).rename(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff0f2ea-8a0c-43e0-aec2-1989a0d3a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output + f'NIS_results_duplicates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bcc19f-694d-411c-b2d5-987f522e06bd",
   "metadata": {},
   "source": [
    "### Optical pooled screens analyis pipeline\n",
    "\n",
    "This requires you to input all the image data for the phenotype and the in-situ cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbf5a0-1224-4987-8831-edf20ef67c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images(img1, img2, targetimage):\n",
    "    images = img1, img2\n",
    "    _, offset = ops.process.Align.calculate_offsets(images, upsample_factor=2)\n",
    "    \n",
    "    img_pad = np.pad(targetimage, mode = 'constant', pad_width = int(np.max(abs(offset)))+1, constant_values = 0)\n",
    "    mx = int(img_pad.shape[0]/2 + offset[0])\n",
    "    my = int(img_pad.shape[0]/2 + offset[1])\n",
    "    return img_pad[mx-1024:mx+1024, my-1024:my+1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a789d0b-9bfd-4f99-87de-e1133692839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_cells(array, cell, WILDCARDS, THRESHOLD_STD = 10):\n",
    "    aligned = Snake._align_SBS(array, method='DAPI')\n",
    "    loged = Snake._transform_log(aligned, sigma = 1, skip_index=0)\n",
    "    maxed = Snake._max_filter(loged, 3, remove_index=0)\n",
    "    std = Snake._compute_std(loged, remove_index=0)\n",
    "    peaks = Snake._find_peaks(std)\n",
    "    df_bases = Snake._extract_bases(maxed, peaks, cell, \n",
    "                        THRESHOLD_STD, wildcards=WILDCARDS)\n",
    "    if len(df_bases)>0:\n",
    "    \n",
    "        df_reads = Snake._call_reads(df_bases)\n",
    "        df_cells = Snake._call_cells(df_reads)\n",
    "        return df_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221311e-5c06-49a2-9394-6310f1b7211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brunello = pd.read_csv('data/starting/brunello_library.txt', sep = '\\t', header = None)\n",
    "brunello[2] = [i[:14] for i in brunello[1]]\n",
    "\n",
    "brunello_scbl = pd.read_csv('data/starting/brunello_library_scrambled.txt', sep = '\\t', header = None)\n",
    "brunello_scbl[2] = [i[:14] for i in brunello_scbl[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba8a6a-acad-4649-b2a9-f3ad0d336e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = ['E3', 'D10', 'D5', 'E2', 'F4', 'G6', 'H7']\n",
    "output = 'data/figE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf89a3-7814-4b46-80b0-12c9c5491849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "res = {'standard': {'G9': 0}, 'scrambled': {'G9': 0}}\n",
    "       \n",
    "for well in wells:\n",
    "    \n",
    "    base = f'/home/jsblab/data2/P41_in-situ/{well}/'\n",
    "    \n",
    "    files = [x for x in os.listdir(base) if not os.path.isdir(base+x)]\n",
    "    \n",
    "    cycles = sorted(list(set([i.split('_')[0] for i in files])), key = lambda x:int(x[5:]))\n",
    "    wells = sorted(list(set([i.split('_')[1] for i in files])), key = lambda x:(x[0],int(x[1])))\n",
    "    tiles = sorted(list(set([i.split('_')[3] for i in files])), key = lambda x:int(x[4:]))\n",
    "    channels = sorted(list(set([i.split('_')[4][7:9] for i in files])), key = lambda x:int(x))\n",
    "\n",
    "    mappings = {'standard':  pd.DataFrame(columns=['tile','mapping_cells', 'cells', 'ratio']),\n",
    "                'scrambled': pd.DataFrame(columns=['tile','mapping_cells', 'cells', 'ratio'])}\n",
    "    \n",
    "    df_stand = pd.DataFrame()\n",
    "    df_scrbl = pd.DataFrame()\n",
    "    df_ = pd.DataFrame()\n",
    "    \n",
    "    for tile in tiles:\n",
    "        \n",
    "        # Open Cell mask and reset array\n",
    "        cells = np.array(Image.open(base + f'channel04/cp_cycle14_{well}_time001_{tile}.tif'))\n",
    "        arr = np.zeros((14,5,2048,2048))\n",
    "        \n",
    "        if np.max(cells) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Load images into array\n",
    "        for cycle_no, cycle in enumerate(cycles):\n",
    "            for channel_no, channel in enumerate(channels):\n",
    "                arr[cycle_no][channel_no] = np.array(Image.open(base + f'{cycle}_{well}_time001_{tile}_channel{channel}.tif'))\n",
    "        \n",
    "        # Align cells from first and 14. cycle\n",
    "        cells = align_images(arr[0][0], arr[13][0], cells)     \n",
    "        \n",
    "        df_ = call_cells(arr, cells, THRESHOLD_STD=100, WILDCARDS = dict(well=f'{well}', tile=f'{tile}'))\n",
    "        dfs_ = call_cells(arr, cells, THRESHOLD_STD=10, WILDCARDS = dict(well=f'{well}', tile=f'{tile}'))\n",
    "        \n",
    "        # If no cells are detected in tile\n",
    "        if df_ is None and dfs_ is None:\n",
    "            mappings['standard'].loc[len(mappings['standard'])]   = [tile, 0, np.max(cells), 0]\n",
    "            mappings['scrambled'].loc[len(mappings['scrambled'])] = [tile, 0, np.max(cells), 0]\n",
    "            continue\n",
    "            \n",
    "        # Concat different thresholds\n",
    "        dfc = pd.concat([df_, dfs_])\n",
    "        dfc = dfc.drop_duplicates(['tile','well','cell'])\n",
    "\n",
    "        # Merge with brunello library\n",
    "        df_stand = df_stand.append(pd.concat([pd.merge(dfc, brunello, left_on='cell_barcode_0', right_on=[2]),\n",
    "                         pd.merge(dfc, brunello, left_on='cell_barcode_1', right_on=[2])]).drop_duplicates(['tile', 'cell']))\n",
    "\n",
    "        df_scrbl = df_scrbl.append(pd.concat([pd.merge(dfc, brunello_scbl, left_on='cell_barcode_0', right_on=[2]),\n",
    "                          pd.merge(dfc, brunello_scbl, left_on='cell_barcode_1', right_on=[2])]).drop_duplicates(['tile', 'cell']))\n",
    "        \n",
    "        \n",
    "        \n",
    "        mappings['standard'].loc[len(mappings['standard'])]   = [tile, len(df_stand[df_stand.tile == tile]), np.max(cells), len(df_stand[df_stand.tile == tile])/np.max(cells)*100]\n",
    "        mappings['scrambled'].loc[len(mappings['scrambled'])] = [tile, len(df_scrbl[df_scrbl.tile == tile]), np.max(cells), len(df_scrbl[df_scrbl.tile == tile])/np.max(cells)*100]\n",
    "        \n",
    "    # Remove tiles with low amount of cells\n",
    "    for x in ['standard', 'scrambled']:\n",
    "        mappings[x] = mappings[x][mappings[x]['mapping_cells'] >= (np.percentile(mappings[x]['mapping_cells'], 50)/10)]\n",
    "\n",
    "    mappings['standard'].to_csv(output + f'insitu_{well}_mapping.csv')\n",
    "    mappings['scrambled'].to_csv(output + f'insitu_{well}_mapping_scrbl.csv')\n",
    "    df_stand.to_csv(output + f'insitu_{well}_all_cells.csv')\n",
    "    df_scrbl.to_csv(output + f'insitu_{well}_all_cells_scrbl.csv')\n",
    "        \n",
    "    # Merge with cell assignment data\n",
    "    assignment = pd.read_csv(f'data/starting/figE/insitu/P41_{well}_CellAssignments.txt', sep = '\\t')\n",
    "    \n",
    "    df_stand['tile'] = df_stand.tile.str[4:].astype(int)-1\n",
    "    df_scrbl['tile'] = df_scrbl.tile.str[4:].astype(int)-1\n",
    "\n",
    "    df_stand = assignment.merge(df_stand, left_on = ['in-situ_tile','cell'], right_on = ['tile','cell'])\n",
    "    df_scrbl = assignment.merge(df_scrbl, left_on = ['in-situ_tile','cell'], right_on = ['tile','cell'])\n",
    "\n",
    "    # Calculate mean in first halve and second\n",
    "    for x in ['standard', 'scrambled']:\n",
    "\n",
    "        sum_cells_front = sum([i for i in mappings[x].cells][:len(mappings[x])//2])\n",
    "        sum_mapped_front = sum([i for i in mappings[x]['mapping_cells']][:len(mappings[x])//2])\n",
    "        sum_cells_back = sum([i for i in mappings[x].cells][len(mappings[x])//2:])\n",
    "        sum_mapped_back = sum([i for i in mappings[x]['mapping_cells']][len(mappings[x])//2:])\n",
    "\n",
    "        res[x][well] = [sum_mapped_front/sum_cells_front*100, sum_mapped_back/sum_cells_back*100]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6ff0b-ba72-42e5-8664-c463976ada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {'E2': 'MC-38', 'E3': 'MaMeI65', 'F4': 'B16-F1', 'D5': 'PC-3', 'G6': 'THP1', 'H7': 'iMac', 'D10': 'HeLa', 'G9': 'Primary'}\n",
    "\n",
    "df = pd.DataFrame(res['standard']).T.rename({0: 'standard', 1: 'standard'}, axis=1)\n",
    "df['0'] = pd.DataFrame(res['scrambled']).T[0]\n",
    "df['1'] = pd.DataFrame(res['scrambled']).T[1]\n",
    "\n",
    "df = df.rename({'0': 'scrambled', '1': 'scrambled'}, axis=1).rename(name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875013bc-2de5-4eea-89cc-4c9fab5b7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output + f'final_insitu_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d074b-ae1d-4d85-91ef-ab59ecc8fd98",
   "metadata": {},
   "source": [
    "### Generate final figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9f70e-da06-4924-bdea-08782d016838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load insitu and nis data and reformat columns\n",
    "df_insitu = pd.read_csv(output + 'insitu_results_duplicates.csv', index_col=0).loc[['HeLa', 'MaMeI65', 'B16-F1', 'THP1', 'PC-3', 'iMac', 'MC-38', 'Primary']]\n",
    "df_nis = pd.read_csv(output + 'NIS_results_duplicates.csv', index_col=0).loc[['HeLa', 'MaMeI65', 'B16-F1', 'THP1', 'PC-3', 'iMac', 'MC-38', 'Primary']]\n",
    "\n",
    "# Reformat tables\n",
    "resdf = {'cell': [], 'method': [], 'perc': []}\n",
    "\n",
    "for df, name in zip([df_nis, df_insitu], ['NIS', 'insitu']):\n",
    "    for i, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            resdf['cell'].append(i)\n",
    "            resdf['method'].append(f'{name}_scrambled' if 'scrambled' in col else name)\n",
    "            resdf['perc'].append(row[col])\n",
    "        \n",
    "df = pd.DataFrame(resdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876633c-5e9e-4f0e-8cbb-d37d5d03ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Figure E\n",
    "g = sns.catplot(data=df, kind=\"bar\", x=\"cell\", y=\"perc\", hue=\"method\", palette=\"dark\", alpha=.6, height=7, aspect=15/10)\n",
    "g.set_axis_labels('', 'Nuclei with library barcode (%)')\n",
    "g.set_titles('Figure E')\n",
    "g.set(ylim=(0, 80))\n",
    "\n",
    "plt.savefig(f'data/figE/FigureE_AH.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
